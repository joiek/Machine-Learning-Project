{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceae00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1c7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GraphConv featuriser - splitting the training dataset into smaller datasets\n",
    "# tasks, datasets, transformers = dc.molnet.load_tox21(\n",
    "#     featurizer='GraphConv', \n",
    "#     save_dir=r'C:\\Users\\ym20201\\Documents\\Datasets',\n",
    "#     data_dir=r'C:\\Users\\ym20201\\Documents\\Datasets')\n",
    "# splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "# train_data, valid_data,test_data = splitter.train_valid_test_split(\n",
    "#     datasets[0], \n",
    "#     frac_train = 0.8, frac_valid = 0.08, frac_test = 0.12)\n",
    "\n",
    "\n",
    "# # model = dc.models.GraphConvModel(n_tasks=12, mode='regression', dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0047b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:16:47] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "#GraphConv featuriser - splitting the training dataset into smaller datasets\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(\n",
    "    save_dir=r'C:\\Users\\ym20201\\Documents\\Datasets',\n",
    "    data_dir=r'C:\\Users\\ym20201\\Documents\\Datasets')\n",
    "\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "train_data, valid_data,test_data = splitter.train_valid_test_split(\n",
    "    datasets[0], \n",
    "    frac_train = 0.8, frac_valid = 0.08, frac_test = 0.12)\n",
    "\n",
    "#Featurisation using ConvMolFeaturizer\n",
    "train_feat = featurizer.featurize(train_data.ids)\n",
    "valid_feat = featurizer.featurize(valid_data.ids)\n",
    "test_feat = featurizer.featurize(test_data.ids)\n",
    "\n",
    "# model = dc.models.GraphConvModel(n_tasks=12, mode='regression', dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7828051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepchem.feat.mol_graphs.ConvMol at 0x255a193a648>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #epoch - number of times data is shown to NN\n",
    "# model.fit(train_data, nb_epoch=10) #training model\n",
    "train_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d0988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor = tf.convert_to_tensor(train_data.ids[0])\n",
    "# tensor = tf.convert_to_tensor(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e45ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Converting numpy array to tensor\n",
    "# train_tensor = []\n",
    "# for i in range(len(train_feat)):\n",
    "#     tensor = tf.convert_to_tensor(train_feat[i])\n",
    "#     train_tensor.append(tensor)\n",
    "    \n",
    "# valid_tensor = []\n",
    "# for i in range(len(valid_feat)):\n",
    "#     tensor_v = tf.convert_to_tensor(valid_feat[i])\n",
    "#     valid_tensor.append(tensor_v)\n",
    "    \n",
    "# test_tensor = []\n",
    "# for i in range(len(test_feat)):\n",
    "#     tensor_t = tf.convert_to_tensor(test_feat[i])\n",
    "#     test_tensor.append(tensor_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de48bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "# print(\"Training set score:\", model.evaluate(train_data, [metric], transformers))\n",
    "# print(\"Test set score:\", model.evaluate(test_data, [metric], transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46d54920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the model\n",
    "# keras_model = Sequential([\n",
    "#     layers.Dense(50, activation='relu'), # hidden layer\n",
    "#     layers.Dense(1) # output layer\n",
    "# ])\n",
    "\n",
    "# model = dc.models.KerasModel(keras_model, dc.models.losses.L1Loss())\n",
    "# model.fit(train_feat, nb_epoch=10)\n",
    "\n",
    "keras_model = Sequential()\n",
    "keras_model.add(layers.Conv2D(filters=32,\n",
    "                          kernel_size=3,\n",
    "                          activation='relu',\n",
    "                          dilation_rate=2,\n",
    "                             input_shape=(80, 80, 1)))\n",
    "keras_model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "#dropout to avoid overfitting\n",
    "keras_model.add(layers.Dense(50, activation='relu'))\n",
    "keras_model.add(layers.Dense(1))\n",
    "\n",
    "keras_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a62fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 76, 76, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 38, 38, 50)        1650      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 38, 38, 1)         51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,021\n",
      "Trainable params: 2,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "591367f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(train_feat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a398da73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type ConvMol).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12944\\1039234800.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                validation_data=(valid_feat,valid_feat))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tdaf-tf2p7\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tdaf-tf2p7\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type ConvMol)."
     ]
    }
   ],
   "source": [
    "keras_model.fit(x=train_feat, y=train_feat,\n",
    "                epochs=10,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "               validation_data=(valid_feat,valid_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1455370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0588f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
